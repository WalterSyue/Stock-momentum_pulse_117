#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
tw_stock_pipeline.py
å°å£è›‹å°è‚¡çµ‚æ¥µç­–ç•¥ï¼š
- å…¨å¸‚å ´æƒæ + äº”å¤§é€²å ´æ¢ä»¶ + æ³•äººå››é€± A+Bï¼ˆA åªç•¶åƒè€ƒè³‡è¨Šï¼Œä¸æ˜¯ç¡¬æ¢ä»¶ï¼‰
- å‡ºå ´è¨Šè™Ÿï¼ˆåªå°ä½ æŒæœ‰æ¸…å–®æ¨æ’­ï¼‰
- Telegram å¡ç‰‡æ¨æ’­ï¼ˆä¸­æ–‡ï¼‰
- valid_tw_codes åå–® + cache + error blacklist
- ç°¡æ˜“å–®æª”å›æ¸¬ï¼šç¸½å ±é…¬ç‡ / å‹ç‡ / å¹´åŒ–å ±é…¬ç‡
"""

import os
import sys
import re
import io
import csv
import time
import json
import datetime as dt
from typing import List, Optional, Dict, Any

import numpy as np
import pandas as pd

# ============================================================
# ä¾è³´å¥—ä»¶è‡ªå‹•ç¢ºèªï¼ˆrequests / yfinance / pyyamlï¼‰
# ============================================================

def _ensure_pkgs():
    missing = []
    try:
        import requests  # noqa
    except Exception:
        missing.append("requests")
    try:
        import yfinance  # noqa
    except Exception:
        missing.append("yfinance")
    try:
        import yaml  # noqa
    except Exception:
        missing.append("pyyaml")
    if missing:
        import subprocess
        subprocess.check_call(
            [sys.executable, "-m", "pip", "install", *missing, "-q"]
        )

_ensure_pkgs()
import requests  # type: ignore
import yfinance as yf  # type: ignore
try:
    import yaml  # type: ignore
    HAS_YAML = True
except Exception:
    HAS_YAML = False

# ============================================================
# å…¨åŸŸè¨­å®š / æª”æ¡ˆè·¯å¾‘
# ============================================================

CACHE_DIR = "cache"
VALID_CODES_FILE = "valid_tw_codes.txt"
ERROR_CODES_FILE = "error_codes.txt"
HELD_STOCKS_FILE = "held_stocks.txt"

os.makedirs(CACHE_DIR, exist_ok=True)

UA = {"User-Agent": "Mozilla/5.0 (compatible; tw-stock-pipeline/ultimate/1.0)"}

TWSE_LIST_URL = "https://openapi.twse.com.tw/v1/opendata/t187ap03_L"
TPEX_LIST_URL = "https://www.tpex.org.tw/openapi/v1/company_basic_info"

TWSE_DAY_K = "https://www.twse.com.tw/rwd/zh/afterTrading/STOCK_DAY?date={date}&stockNo={code}"
TPEX_DAY_K = "https://www.tpex.org.tw/web/stock/aftertrading/daily_close_quotes/stk_quote_result.php?l=zh-tw&d={date}&s={code}"

# ============================================================
# é è¨­è¨­å®šï¼ˆå¯è¢« config.yaml è¦†å¯«ï¼‰
# ============================================================

DEFAULT_CFG: Dict[str, Any] = {
    # é€²å ´æŒ‡æ¨™
    "ema_period": 117,
    "vol_fast": 5,
    "vol_slow": 10,
    "kd_n": 9,
    "kd_k": 3,
    "kd_d": 3,
    "kmin": 20.0,
    "kmax": 80.0,
    "dmin": 20.0,
    "dmax": 80.0,
    "adx_period": 14,
    "adx_min": 33.0,
    "macd_fast": 12,
    "macd_slow": 26,
    "macd_signal": 9,
    "macd_require_positive": True,
    "macd_require_cross": True,

    # å‡ºå ´æ¢ä»¶
    "exit_ema_break_bars": 2,
    "exit_volume_fade": True,
    "exit_macd_flip": True,
    "exit_adx_weaken": True,
    "exit_adx_weak_threshold": 25.0,
    "exit_adx_weak_bars": 3,
    "exit_kd_death_high": True,

    # åœæ / è¿½è¹¤åœæ
    "stop_atr_period": 14,
    "stop_atr_mult": 2.0,
    "trail_use_ema": True,
    "trail_ema_period": 50,

    # è©•åˆ†æ¬Šé‡ï¼ˆæŠ€è¡“é¢ï¼‰
    "score_w_trend": 0.3,
    "score_w_vol": 0.2,
    "score_w_adx": 0.3,
    "score_w_macd": 0.2,

    # Telegram æ¨æ’­
    "telegram_token": None,
    "telegram_chat_id": None,
    "notify_on_entry": True,
    "notify_on_exit": True,

    # å›æ¸¬è¨­å®š
    "enable_backtest": False,
    "backtest_initial_capital": 1_000_000.0,
    "backtest_risk_per_trade": 0.1,
    "backtest_commission_pct": 0.001,
    "backtest_slippage_pct": 0.001,
    "backtest_max_positions": 1,
    "backtest_min_holding_days": 3,

    # æ³•äººç›¸é—œè¨­å®šï¼ˆA = å››é€±è²·è¶…è³‡è¨Šï¼ŒB = è©•åˆ†ï¼Œä¸ç•¶ç¡¬æ¢ä»¶ï¼‰
    "score_w_inst": 0.0,               # Bï¼šæ³•äººå¼·åº¦è©•åˆ†æ¬Šé‡ï¼ˆ0 = åªç•¶è³‡è¨Šï¼‰
    "inst_lookback": 20,               # çœ‹ 20 å€‹äº¤æ˜“æ—¥ â‰’ 4 é€±
    "inst_flow_file": "inst_flow.csv", # ä¸‰å¤§æ³•äººè³‡æ–™æª”
    "inst_norm": 5000.0,               # æ­£è¦åŒ–åŸºæº–ï¼Œè²·è¶…è¶Šå¤§ inst_score è¶Šé«˜
}

CN_COND_NAMES = {
    "cond1": "è‚¡åƒ¹é«˜æ–¼EMA",
    "cond2": "æˆäº¤é‡æ”¾å¤§",
    "cond3": "KDåˆç†å€é–“",
    "cond4": "è¶¨å‹¢å¼·å‹",
    "cond5": "MACDå¤šé ­",
    "cond6": "æ³•äºº4é€±è²·è¶…ç‚ºæ­£",   # åªåšè³‡è¨Šï¼Œä¸åšç¡¬æ¢ä»¶
}

EXIT_REASON_MAP = {
    "trend_break_EMA": "è‚¡åƒ¹é€£çºŒå¤šå¤©è·Œç ´ EMAï¼Œè¶¨å‹¢è½‰å¼±",
    "volume_fade": "æˆäº¤é‡æ˜é¡¯ç¸®å°ä¸”è·Œç ´ MA5ï¼Œè²·ç›¤åŠ›é“æ¸›å¼±",
    "macd_flip_down": "MACD ç”±å¤šç¿»ç©ºï¼Œå‹•èƒ½è½‰å¼±",
    "adx_below_threshold": "ADX ä½æ–¼é–€æª»ï¼Œè¶¨å‹¢åŠ›é“ä¸è¶³",
    "adx_weaken": "ADX é€£çºŒå¤šå¤©èµ°å¼±ï¼Œè¶¨å‹¢è½‰ç–²",
    "kd_death_cross_>80": "KD é«˜æª”ï¼ˆ>80ï¼‰å‡ºç¾æ­»äº¡äº¤å‰ï¼ŒçŸ­ç·šè½‰å¼±",
}

# ============================================================
# é€šç”¨å°å·¥å…·
# ============================================================

def save_text(path: str, content: str) -> None:
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)


def last_scalar(x) -> float:
    """å®‰å…¨æ‹¿æœ€å¾Œä¸€å€‹æ•¸å€¼ï¼Œè½‰ floatï¼Œå¤±æ•—å°± NaNã€‚"""
    try:
        if isinstance(x, pd.Series):
            val = x.iloc[-1]
        elif isinstance(x, (list, tuple, np.ndarray)):
            if len(x) == 0:
                return float("nan")
            val = x[-1]
        else:
            val = x
        arr = pd.to_numeric([val], errors="coerce").values
        return float(arr[0]) if arr.size else float("nan")
    except Exception:
        try:
            return float(np.asarray(x).reshape(-1)[-1])
        except Exception:
            return float("nan")


# ============================================================
# é»‘åå–® / æœ‰æ•ˆæ¸…å–® / æŒè‚¡æ¸…å–®
# ============================================================

def load_error_codes() -> set:
    if not os.path.exists(ERROR_CODES_FILE):
        return set()
    lines = open(ERROR_CODES_FILE, "r", encoding="utf-8").read().splitlines()
    return {ln.strip() for ln in lines if ln.strip()}


def save_error_code(code: str) -> None:
    with open(ERROR_CODES_FILE, "a", encoding="utf-8") as f:
        f.write(code + "\n")


def load_valid_codes() -> Optional[List[str]]:
    if not os.path.exists(VALID_CODES_FILE):
        return None
    lines = open(VALID_CODES_FILE, "r", encoding="utf-8").read().splitlines()
    return [ln.strip() for ln in lines if ln.strip()]


def save_valid_codes(codes: List[str]) -> None:
    with open(VALID_CODES_FILE, "w", encoding="utf-8") as f:
        for c in sorted(set(codes)):
            f.write(c + "\n")


def load_held_stocks(path: str = HELD_STOCKS_FILE) -> set:
    """
    è®€å–æŒè‚¡æ¸…å–®ï¼š
    - å¯ä»¥å¯« 2330 æˆ– 2330.TW
    - é€™è£¡çµ±ä¸€åªè¨˜ã€Œæ•¸å­—ä»£ç¢¼ã€æ–¹ä¾¿æ¯”å°
    """
    if not os.path.exists(path):
        return set()
    roots = set()
    for ln in open(path, "r", encoding="utf-8"):
        s = ln.strip()
        if not s or s.startswith("#"):
            continue
        m = re.search(r"(\d+)", s)
        if m:
            roots.add(m.group(1))
    return roots


# ============================================================
# ä¸‹è¼‰ TWSE / TPEX è‚¡ç¥¨ä»£ç¢¼ï¼ˆå»ºç«‹ valid_tw_codes.txtï¼‰
# ============================================================

def load_all_tw_codes() -> List[str]:
    codes = load_valid_codes()
    if codes is not None:
        return codes

    print("âš  æœªç™¼ç¾ valid_tw_codes.txt â†’ æ­£åœ¨å¾ TWSE / TPEx æŠ“å–ä»£ç¢¼â€¦")

    all_codes: List[str] = []

    # TWSE
    try:
        r = requests.get(TWSE_LIST_URL, headers=UA, timeout=20)
        js = r.json()
        if isinstance(js, list):
            for row in js:
                c = str(row.get("å…¬å¸ä»£è™Ÿ") or "").strip()
                if c.isdigit():
                    all_codes.append(f"{c}.TW")
    except Exception as e:
        print(f"[è­¦å‘Š] TWSE ä»£ç¢¼æŠ“å–å¤±æ•—ï¼š{e}")

    # TPEX
    try:
        r = requests.get(TPEX_LIST_URL, headers=UA, timeout=20)
        js = r.json()
        if isinstance(js, list):
            for row in js:
                c = str(row.get("code") or "").strip()
                if c.isdigit():
                    all_codes.append(f"{c}.TWO")
    except Exception as e:
        print(f"[è­¦å‘Š] TPEx ä»£ç¢¼æŠ“å–å¤±æ•—ï¼š{e}")

    all_codes = sorted(set(all_codes))
    save_valid_codes(all_codes)
    print(f"âœ” å·²å»ºç«‹ valid_tw_codes.txtï¼ˆå…± {len(all_codes)} æª”ï¼‰")
    return all_codes


# ============================================================
# Cache æ”¯æ´
# ============================================================

def load_from_cache(code: str) -> Optional[pd.DataFrame]:
    path = os.path.join(CACHE_DIR, f"{code}.csv")
    if not os.path.exists(path):
        return None
    try:
        df = pd.read_csv(path, parse_dates=["æ—¥æœŸ"])
        df = df.set_index("æ—¥æœŸ")
        return df
    except Exception:
        return None


def save_to_cache(code: str, df: pd.DataFrame) -> None:
    path = os.path.join(CACHE_DIR, f"{code}.csv")
    df.to_csv(path, encoding="utf-8-sig")


# ============================================================
# åƒ¹æ ¼ä¸‹è¼‰ï¼šYahoo + Fallbackï¼ˆTWSE / TPExï¼‰
# ============================================================

def _fix_tz(df: pd.DataFrame) -> pd.DataFrame:
    if getattr(df.index, "tz", None) is not None:
        df = df.tz_localize(None)
    return df.dropna()


def yahoo_download(code: str, start: str, end: str) -> Optional[pd.DataFrame]:
    try:
        df = yf.download(code, start=start, end=end, progress=False, auto_adjust=False, threads=False)
        if df is not None and not df.empty:
            df = _fix_tz(df)
            df.index.name = "æ—¥æœŸ"
            return df
    except Exception:
        pass
    # fallback æœŸé–“æ¨¡å¼
    for period in ["5y", "2y", "max"]:
        try:
            df = yf.download(code, period=period, interval="1d", progress=False, auto_adjust=False, threads=False)
            if df is not None and not df.empty:
                df = _fix_tz(df)
                df.index.name = "æ—¥æœŸ"
                try:
                    s = pd.to_datetime(start)
                    e = pd.to_datetime(end)
                    df = df.loc[(df.index >= s) & (df.index <= e)]
                except Exception:
                    pass
                if not df.empty:
                    return df
        except Exception:
            time.sleep(0.3)
            continue
    return None


def twse_download(code: str, years: List[int]) -> Optional[pd.DataFrame]:
    dfs = []
    for y in years:
        for m in range(1, 13):
            date = f"{y}{m:02d}01"
            url = TWSE_DAY_K.format(date=date, code=code)
            try:
                r = requests.get(url, headers=UA, timeout=10)
                if r.status_code != 200:
                    continue
                data = r.json()
                if "data" not in data:
                    continue
                rows = data["data"]
                df = pd.DataFrame(rows, columns=[
                    "æ—¥æœŸ", "æˆäº¤è‚¡æ•¸", "æˆäº¤é‡‘é¡", "é–‹ç›¤åƒ¹",
                    "æœ€é«˜åƒ¹", "æœ€ä½åƒ¹", "æ”¶ç›¤åƒ¹", "æ¼²è·Œ", "æˆäº¤ç­†æ•¸"
                ])
                df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"].str.replace("/", "-"))
                df = df.rename(columns={
                    "é–‹ç›¤åƒ¹": "Open",
                    "æœ€é«˜åƒ¹": "High",
                    "æœ€ä½åƒ¹": "Low",
                    "æ”¶ç›¤åƒ¹": "Close",
                    "æˆäº¤è‚¡æ•¸": "Volume",
                })
                for col in ["Open", "High", "Low", "Close", "Volume"]:
                    df[col] = pd.to_numeric(df[col].str.replace(",", ""), errors="coerce")
                df = df.dropna(subset=["Close"])
                dfs.append(df)
            except Exception:
                continue
    if not dfs:
        return None
    df_all = pd.concat(dfs)
    df_all = df_all.sort_values("æ—¥æœŸ").set_index("æ—¥æœŸ")
    return df_all


def tpex_download(code: str, years: List[int]) -> Optional[pd.DataFrame]:
    # ç°¡å–®ç‰ˆï¼šå¯¦å‹™ä¸Š TPEx fallback è¼ƒåƒ APIï¼Œé€™é‚Šèµ°æ¥µç°¡æ¨¡å¼
    # è‹¥è¦æ›´å¼·å¯å†å¼·åŒ–
    return None  # å…ˆé—œé–‰ï¼Œä¸»è¦ä¾è³´ Yahoo


def fallback_download(code: str, start: str, end: str) -> Optional[pd.DataFrame]:
    years = list(range(int(start[:4]), dt.date.today().year + 1))
    if code.endswith(".TW"):
        base = code.replace(".TW", "")
        df = twse_download(base, years)
    else:
        base = code.replace(".TWO", "")
        df = tpex_download(base, years)
    if df is None:
        return None
    # è£åˆ‡æ—¥æœŸ
    try:
        s = pd.to_datetime(start)
        e = pd.to_datetime(end)
        df = df.loc[(df.index >= s) & (df.index <= e)]
    except Exception:
        pass
    return df if not df.empty else None


def load_price(code: str, start: str, end: str) -> Optional[pd.DataFrame]:
    """
    å®Œæ•´æµç¨‹ï¼šé»‘åå–®åˆ¤æ–· â†’ cache â†’ Yahoo â†’ fallback â†’ é»‘åå–®ç´€éŒ„
    """
    error_codes = load_error_codes()
    if code in error_codes:
        print(f"[SKIP] {code} åœ¨é»‘åå–®ä¸­ï¼Œç•¥é")
        return None

    # å…ˆè©¦ cache
    df_cache = load_from_cache(code)
    if df_cache is not None and not df_cache.empty:
        last_day = df_cache.index.max().date()
        end_day = pd.to_datetime(end).date()
        # cache å·²æ¶µè“‹ â†’ ç›´æ¥ç”¨
        if last_day >= end_day:
            return df_cache
        # è£œæ–°çš„éƒ¨ä»½
        start_dl = (last_day + dt.timedelta(days=1)).isoformat()
        df_new = yahoo_download(code, start_dl, end)
        if df_new is not None and not df_new.empty:
            df_all = pd.concat([df_cache, df_new])
            df_all = df_all[~df_all.index.duplicated(keep="last")].sort_index()
            save_to_cache(code, df_all)
            return df_all
        # Yahoo è£œä¸åˆ° â†’ è©¦ fallback
        df_fb = fallback_download(code, start_dl, end)
        if df_fb is not None and not df_fb.empty:
            df_all = pd.concat([df_cache, df_fb])
            df_all = df_all[~df_all.index.duplicated(keep="last")].sort_index()
            save_to_cache(code, df_all)
            return df_all
        # éƒ½å¤±æ•— â†’ é»‘åå–®
        save_error_code(code)
        return None

    # cache æ²’æœ‰ â†’ ç›´æ¥ Yahoo
    df_yf = yahoo_download(code, start, end)
    if df_yf is not None and not df_yf.empty:
        save_to_cache(code, df_yf)
        return df_yf

    # Yahoo å¤±æ•— â†’ fallback
    df_fb = fallback_download(code, start, end)
    if df_fb is not None and not df_fb.empty:
        save_to_cache(code, df_fb)
        return df_fb

    save_error_code(code)
    return None


# ============================================================
# æ³•äººè³‡æ–™ï¼šè‡ªå‹•æŠ“ TWSE T86 + è®€å…¥ inst_flow.csv
# ============================================================

def build_inst_flow(start: str, end: str, out_path: str) -> None:
    """
    è‡ªå‹•æŠ“ TWSE ä¸‰å¤§æ³•äºº T86ï¼Œç”¢å‡º inst_flow.csv

    ä½¿ç”¨ APIï¼š
    https://www.twse.com.tw/rwd/zh/fund/T86?date=YYYYMMDD&selectType=ALL

    ç”¢å‡ºæ¬„ä½ï¼š
    date, code, net_inst   ï¼ˆnet_inst = ä¸‰å¤§æ³•äººè²·è³£è¶…ã€Œå¼µæ•¸ã€ï¼‰
    æ³¨æ„ï¼šT86 å›å‚³å–®ä½æ˜¯ã€Œè‚¡æ•¸ã€ï¼Œé€™è£¡çµ±ä¸€é™¤ä»¥ 1000 è½‰æˆã€Œå¼µã€ã€‚
    """
    print(f"ğŸ“¥ build_inst_flowï¼šå¾ {start} åˆ° {end} æŠ“å– TWSE ä¸‰å¤§æ³•äººè³‡æ–™â€¦")

    try:
        d_start = dt.datetime.strptime(start, "%Y-%m-%d").date()
        d_end   = dt.datetime.strptime(end, "%Y-%m-%d").date()
    except Exception as e:
        print(f"âš  build_inst_flowï¼šæ—¥æœŸæ ¼å¼éŒ¯èª¤ {e}ï¼Œä¸ç”¢ç”Ÿæ³•äººè³‡æ–™")
        return

    records = []
    cur = d_start
    while cur <= d_end:
        # é€±æœ«è·³é
        if cur.weekday() >= 5:
            cur += dt.timedelta(days=1)
            continue

        dstr = cur.strftime("%Y%m%d")
        url = f"https://www.twse.com.tw/rwd/zh/fund/T86?date={dstr}&selectType=ALL"

        try:
            r = requests.get(url, headers=UA, timeout=15)
            js = r.json()
            data = js.get("data") or []
            if not data:
                print(f"[æ³•äºº] {cur} ç„¡è³‡æ–™ï¼ˆå¯èƒ½éäº¤æ˜“æ—¥ / API ç„¡å›å‚³ï¼‰")
                cur += dt.timedelta(days=1)
                continue

            for row in data:
                code = str(row[0]).strip()
                if not code or not code[0].isdigit():
                    continue

                # T86 æœ€å¾Œä¸€æ¬„æ˜¯ã€Œä¸‰å¤§æ³•äººè²·è³£è¶…è‚¡æ•¸åˆè¨ˆã€
                net_str = str(row[-1]).replace(",", "")
                try:
                    net_shares = int(net_str)       # è‚¡æ•¸
                except Exception:
                    continue

                net_lots = net_shares / 1000.0     # è½‰æˆã€Œå¼µã€
                records.append({
                    "date": cur.isoformat(),
                    "code": code,
                    "net_inst": net_lots,
                })

            print(f"[æ³•äºº] {cur} æŠ“å–æˆåŠŸï¼Œ{len(data)} æª”")
            time.sleep(0.3)

        except Exception as e:
            print(f"[æ³•äºº] {cur} æŠ“å–å¤±æ•—ï¼š{e}")
            time.sleep(1.0)

        cur += dt.timedelta(days=1)

    if not records:
        print("âš  build_inst_flowï¼šæ²’æœ‰æŠ“åˆ°ä»»ä½•æ³•äººè³‡æ–™ï¼Œinst_flow.csv ä¸æœƒæ›´æ–°")
        return

    df = pd.DataFrame(records)
    df.to_csv(out_path, index=False, encoding="utf-8-sig")
    print(f"âœ” å·²è¼¸å‡ºä¸‰å¤§æ³•äººè³‡æ–™ â†’ {out_path}ï¼ˆå…± {len(df)} ç­†è¨˜éŒ„ï¼‰")



def load_inst_data(path: str) -> Optional[pd.DataFrame]:
    """
    è®€ä¸‰å¤§æ³•äººè³‡æ–™æª” inst_flow.csv

    é æœŸæ ¼å¼ï¼š
    date,code,net_inst
    2023-01-02,2330,1234
    2023-01-02,2603,-500
    ...
    """
    if not os.path.exists(path):
        print(f"âš  æ‰¾ä¸åˆ°æ³•äººè³‡æ–™æª”ï¼š{path}ï¼Œå°‡ç•¥éæ³•äººè³‡è¨Šèˆ‡è©•åˆ†")
        return None

    df = pd.read_csv(path, dtype={"code": str})
    if "date" not in df.columns or "code" not in df.columns:
        print("âš  inst_flow æª”ç¼ºå°‘ date / code æ¬„ä½ï¼Œç•¥éæ³•äººåŠŸèƒ½")
        return None

    if "net_inst" not in df.columns:
        print("âš  inst_flow æª”æ²’æœ‰ net_inst æ¬„ä½ï¼Œç•¥éæ³•äººåŠŸèƒ½")
        return None

    df["date"] = pd.to_datetime(df["date"])
    df = df.sort_values(["code", "date"])
    df = df.set_index(["date", "code"])  # MultiIndex
    return df


def get_inst_series_for_code(inst_df: Optional[pd.DataFrame],
                             code: str,
                             index: pd.DatetimeIndex) -> Optional[pd.Series]:
    """
    å¾æ³•äºº DataFrame è£¡ï¼Œå–å‡ºå–®ä¸€è‚¡ç¥¨çš„ daily net_instï¼Œ
    ä¸¦å°é½Šåˆ°åƒ¹æ ¼ df çš„ indexï¼ˆæ—¥æœŸï¼‰ã€‚
    """
    if inst_df is None:
        return None

    m = re.match(r"(\d+)", code)
    root = m.group(1) if m else None
    if not root:
        return None

    try:
        s = inst_df.xs(root, level="code")["net_inst"]
    except KeyError:
        return None

    s = s.reindex(index).fillna(0.0)
    s.name = "net_inst"
    return s


# ============================================================
# æŠ€è¡“æŒ‡æ¨™
# ============================================================

def ema(s: pd.Series, span: int) -> pd.Series:
    return s.ewm(span=span, adjust=False).mean()


def true_range(h: pd.Series, l: pd.Series, c: pd.Series) -> pd.Series:
    pc = c.shift(1)
    tr1 = h - l
    tr2 = (h - pc).abs()
    tr3 = (l - pc).abs()
    return pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)


def atr(h: pd.Series, l: pd.Series, c: pd.Series, n: int = 14) -> pd.Series:
    return true_range(h, l, c).rolling(n).mean()


def adx(h: pd.Series, l: pd.Series, c: pd.Series, n: int = 14) -> pd.Series:
    """å¼·åŒ–ç‰ˆ ADXï¼šå¼·åˆ¶ 1D numpyï¼Œé¿å… (N,1) ç¶­åº¦å•é¡Œ"""
    up = h.diff().to_numpy().reshape(-1)
    down = (-l.diff()).to_numpy().reshape(-1)

    plus_dm = np.where((up > down) & (up > 0), up, 0.0)
    minus_dm = np.where((down > up) & (down > 0), down, 0.0)

    plus_dm_s = pd.Series(plus_dm, index=h.index).abs()
    minus_dm_s = pd.Series(minus_dm, index=h.index).abs()

    tr = true_range(h, l, c)
    atr_v = tr.rolling(n).mean()

    plus_di = 100 * plus_dm_s.rolling(n).sum() / atr_v
    minus_di = 100 * minus_dm_s.rolling(n).sum() / atr_v

    dx = 100 * (plus_di - minus_di).abs() / (plus_di + minus_di)
    return dx.rolling(n).mean()


def stochastic_kd(h: pd.Series, l: pd.Series, c: pd.Series,
                  n: int = 9, k_smooth: int = 3, d_smooth: int = 3):
    ll = l.rolling(n).min()
    hh = h.rolling(n).max()
    fast_k = 100 * (c - ll) / (hh - ll)
    k = fast_k.rolling(k_smooth).mean()
    d = k.rolling(d_smooth).mean()
    return k, d


def macd(c: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):
    fast_ = ema(c, fast)
    slow_ = ema(c, slow)
    macd_line = fast_ - slow_
    signal_line = ema(macd_line, signal)
    hist = macd_line - signal_line
    return macd_line, signal_line, hist


# ============================================================
# Telegram æ¨æ’­
# ============================================================

def tg_send(message: str, cfg: Dict[str, Any]) -> None:
    token = cfg.get("telegram_token")
    chat_id = cfg.get("telegram_chat_id")
    if not token or not chat_id:
        return
    url = f"https://api.telegram.org/bot{token}/sendMessage"
    payload = {
        "chat_id": chat_id,
        "text": message,
        "parse_mode": "HTML",
        "disable_web_page_preview": True,
    }
    try:
        requests.post(url, data=payload, timeout=10)
    except Exception:
        pass


def format_entry_card(code: str, m: Dict[str, Any]) -> str:
    """é€²å ´è¨Šè™Ÿå¡ç‰‡ï¼ˆTelegram HTML æ ¼å¼ï¼‰"""
    ema_period = int(m.get("ema_period", 117))
    inst_4w = m.get("æ³•äºº4é€±è²·è¶…", float("nan"))
    if np.isnan(inst_4w):
        inst_text = "è³‡æ–™ä¸è¶³"
    else:
        inst_text = f"{inst_4w:.0f} å¼µ"

    lines = [
        f"ğŸš€ <b>é€²å ´è¨Šè™Ÿï¼š{code}</b>",
        f"ğŸ“… æ—¥æœŸï¼š{m['æ—¥æœŸ']}",
        f"ğŸ’° æ”¶ç›¤ï¼š{m['æ”¶ç›¤']:.2f}",
        f"ğŸ“ˆ EMA{ema_period}ï¼š{m['EMA']:.2f}",
        f"ğŸ” KDï¼šK={m['Kå€¼']:.2f}ï¼ŒD={m['Då€¼']:.2f}",
        f"ğŸ“Š ADXï¼š{m['ADX']:.2f}",
        f"ğŸ¦ æ³•äºº4é€±è²·è¶…ï¼š{inst_text}",
        f"ğŸ“¤ MACDï¼š{m['MACD']:.2f}",
        f"â­ ç¶œåˆè©•åˆ†ï¼š{m.get('ç¶œåˆè©•åˆ†(score)', 0):.3f}",
    ]
    return "\n".join(lines)


def format_exit_card(code: str, m: Dict[str, Any], reasons: List[str]) -> str:
    """å‡ºå ´è¨Šè™Ÿå¡ç‰‡ï¼ˆåªå°æŒè‚¡æ¨ï¼‰"""
    if not reasons:
        reason_block = "ï¼ˆæœªæä¾›è©³ç´°åŸå› ï¼‰"
    else:
        reason_lines = []
        for r in reasons:
            cn = EXIT_REASON_MAP.get(r, r)
            reason_lines.append(f"â€¢ {cn}")
        reason_block = "\n".join(reason_lines)

    lines = [
        f"âš ï¸ <b>å‡ºå ´è¨Šè™Ÿï¼š{code}</b>",
        f"ğŸ“… æ—¥æœŸï¼š{m['æ—¥æœŸ']}",
        f"ğŸ’° æ”¶ç›¤ï¼š{m['æ”¶ç›¤']:.2f}",
        "",
        "ğŸ“Œ <b>å‡ºå ´åŸå› ï¼š</b>",
        reason_block,
    ]
    return "\n".join(lines)


# ============================================================
# ç­–ç•¥æ ¸å¿ƒï¼šé€²å‡ºå ´åˆ¤æ–· + è©•åˆ†ï¼ˆå«æ³•äºº A+Bï¼‰
# ============================================================

def screen_and_exit(df: pd.DataFrame,
                    cfg: Dict[str, Any],
                    inst_series: Optional[pd.Series] = None):
    """
    å›å‚³ï¼š
    - metrics: dictï¼ˆæœƒé€² CSVï¼ŒåŒ…å«å»ºè­°é€²/é€€å ´åƒ¹ + æ³•äººè³‡è¨Šï¼‰
    - entry_pass: bool æ˜¯å¦ç¬¦åˆé€²å ´æ¢ä»¶ï¼ˆğŸ‘‰ åªçœ‹äº”å€‹æŠ€è¡“æ¢ä»¶ï¼‰
    - conds_map: å„æ¢ä»¶çš„ True/Falseï¼ˆcond6 åªæ˜¯æ³•äººè³‡è¨Šï¼‰
    - exit_reasons: list[str] å‡ºå ´ç†ç”±ä»£ç¢¼ï¼ˆçµ¦å›æ¸¬ / æ¨æ’­ç”¨ï¼‰
    """
    df = df.copy()
    df = df[~df.index.duplicated(keep="last")]

    c = df["Close"]
    h = df["High"]
    l = df["Low"]
    v = df["Volume"]

    # ===== æŠ€è¡“æŒ‡æ¨™ =====
    ema_val = ema(c, int(cfg["ema_period"]))
    vol_fast = v.rolling(int(cfg["vol_fast"])).mean()
    vol_slow = v.rolling(int(cfg["vol_slow"])).mean()
    k, d = stochastic_kd(
        h, l, c,
        int(cfg["kd_n"]), int(cfg["kd_k"]), int(cfg["kd_d"])
    )
    adxN = adx(h, l, c, int(cfg["adx_period"]))
    macd_line, sig_line, hist = macd(
        c,
        int(cfg["macd_fast"]),
        int(cfg["macd_slow"]),
        int(cfg["macd_signal"]),
    )
    ma5 = c.rolling(5).mean()
    atr_val = atr(h, l, c, int(cfg["stop_atr_period"]))
    trail_ema = ema(c, int(cfg["trail_ema_period"]))

    # ===== å°¾å€¼æŠ½å‡º =====
    close_last = last_scalar(c)
    ema_last   = last_scalar(ema_val)
    vfast_last = last_scalar(vol_fast)
    vslow_last = last_scalar(vol_slow)
    k_last     = last_scalar(k)
    d_last     = last_scalar(d)
    adx_last   = last_scalar(adxN)
    macd_last  = last_scalar(macd_line)
    sig_last   = last_scalar(sig_line)
    hist_last  = last_scalar(hist)
    ma5_last   = last_scalar(ma5)
    atr_last   = last_scalar(atr_val)
    trail_last = last_scalar(trail_ema)

    latest_day = df.index[-1].date().isoformat()

    # ===== æ³•äºº 4 é€±æ·¨è²·è¶…ï¼ˆAï¼šè³‡è¨Šç”¨ï¼‰ =====
    inst_4w_sum = float("nan")
    if inst_series is not None:
        lookback = int(cfg.get("inst_lookback", 20))
        if len(inst_series.dropna()) >= lookback:
            inst_4w_sum = float(inst_series.rolling(lookback).sum().iloc[-1])

    # ===== åˆå§‹åœæ & å»ºè­°åƒ¹ä½ =====
    init_stop = float("nan")
    if not np.isnan(close_last) and not np.isnan(atr_last):
        init_stop = close_last - float(cfg["stop_atr_mult"]) * atr_last

    # ===== é€²å ´æ¢ä»¶ï¼ˆğŸ‘‰ åƒ…äº”å€‹æŠ€è¡“æ¢ä»¶ï¼‰ =====
    cond1 = close_last >= ema_last
    cond2 = vfast_last >= vslow_last
    cond3 = (
        float(cfg["kmin"]) <= k_last <= float(cfg["kmax"])
        and float(cfg["dmin"]) <= d_last <= float(cfg["dmax"])
    )
    cond4 = adx_last > float(cfg["adx_min"])
    macd_pos   = (macd_last > 0.0) if bool(cfg["macd_require_positive"]) else True
    macd_cross = (macd_last > sig_last) if bool(cfg["macd_require_cross"]) else True
    cond5 = macd_pos and macd_cross

    # cond6ï¼šæ³•äºº4é€±æ˜¯å¦ç‚ºæ­£ï¼Œåªåšè³‡è¨Šï¼Œä¸å½±éŸ¿ entry_pass
    cond6 = False
    if not np.isnan(inst_4w_sum):
        cond6 = inst_4w_sum > 0

    entry_pass = all([cond1, cond2, cond3, cond4, cond5])

    # ===== å‡ºå ´æ¢ä»¶ =====
    exit_reasons: List[str] = []

    # EMA é€£çºŒ N å¤©è·Œç ´
    N = int(cfg["exit_ema_break_bars"])
    if N > 0 and len(c) >= N:
        tail_c   = c.tail(N).to_numpy(dtype=float)
        tail_ema = ema_val.tail(N).to_numpy(dtype=float)
        if np.all(tail_c < tail_ema):
            exit_reasons.append("trend_break_EMA")

    # é‡ç¸® + è·Œç ´ MA5
    if bool(cfg["exit_volume_fade"]) and vfast_last < vslow_last and close_last < ma5_last:
        exit_reasons.append("volume_fade")

    # MACD ç¿»ç©º
    if bool(cfg["exit_macd_flip"]) and (macd_last < sig_last) and (macd_last < 0.0):
        exit_reasons.append("macd_flip_down")

    # ADX å¼±åŒ–
    if bool(cfg["exit_adx_weaken"]):
        if adx_last < float(cfg["exit_adx_weak_threshold"]):
            exit_reasons.append("adx_below_threshold")
        weaken_n = int(cfg["exit_adx_weak_bars"])
        if len(adxN.dropna()) >= weaken_n + 1:
            diffs = adxN.diff().dropna().tail(weaken_n).to_numpy(dtype=float)
            if len(diffs) == weaken_n and np.all(diffs < 0):
                exit_reasons.append("adx_weaken")

    # KD é«˜æª”æ­»äº¡äº¤å‰
    if bool(cfg["exit_kd_death_high"]) and len(k.dropna()) >= 2:
        k_prev = last_scalar(k.iloc[-2])
        d_prev = last_scalar(d.iloc[-2])
        if (k_prev > 80.0) and (k_prev > d_prev) and (k_last < d_last):
            exit_reasons.append("kd_death_cross_>80")

    # ===== ç¶œåˆè©•åˆ†ï¼ˆæŠ€è¡“ + å¯é¸æ³•äºº Bï¼‰ =====
    trend_ratio = close_last / ema_last if ema_last > 0 else 0.0
    vol_ratio   = vfast_last / vslow_last if vslow_last > 0 else 0.0
    adx_ratio   = adx_last / float(cfg["adx_min"]) if float(cfg["adx_min"]) > 0 else 0.0
    macd_mom    = hist_last / close_last if close_last > 0 else 0.0
    macd_mom    = max(0.0, macd_mom)

    trend_ratio = float(np.clip(trend_ratio, 0.0, 2.0))
    vol_ratio   = float(np.clip(vol_ratio,   0.0, 3.0))
    adx_ratio   = float(np.clip(adx_ratio,   0.0, 2.0))

    # Bï¼šæ³•äººå¼·åº¦åˆ†æ•¸ï¼ˆ0~1ï¼‰ï¼Œåªå½±éŸ¿æ’åºï¼Œä¸å½±éŸ¿ entry_pass
    inst_score = 0.0
    if not np.isnan(inst_4w_sum):
        norm = float(cfg.get("inst_norm", 5000.0))
        if norm > 0:
            inst_score_raw = np.tanh(inst_4w_sum / norm)
            inst_score = max(0.0, float(inst_score_raw))

    score = (
        float(cfg["score_w_trend"]) * trend_ratio +
        float(cfg["score_w_vol"])   * vol_ratio   +
        float(cfg["score_w_adx"])   * adx_ratio   +
        float(cfg["score_w_macd"])  * macd_mom    +
        float(cfg.get("score_w_inst", 0.0)) * inst_score
    )

    # ===== çµ„åˆå›å‚³æ¬„ä½ =====
    adx_col_name = f"ADX{int(cfg['adx_period'])}"
    exit_cn_list = [EXIT_REASON_MAP.get(r, r) for r in exit_reasons]

    metrics: Dict[str, Any] = {
        "æ—¥æœŸ": latest_day,
        "æ”¶ç›¤": close_last,
        "EMA": ema_last,
        "ema_period": int(cfg["ema_period"]),
        f"{int(cfg['vol_fast'])}æ—¥å‡é‡": vfast_last,
        f"{int(cfg['vol_slow'])}æ—¥å‡é‡": vslow_last,
        "Kå€¼": k_last,
        "Då€¼": d_last,
        adx_col_name: adx_last,
        "ADX": adx_last,
        "MACD": macd_last,
        "MACDè¨Šè™Ÿ": sig_last,
        "MACDæŸ±": hist_last,
        "åˆå§‹åœæåƒ¹(ATR)": init_stop,
        f"å»ºè­°ç§»å‹•åœæ(EMA{int(cfg['trail_ema_period'])})": trail_last,

        # å»ºè­°é€² / é€€å ´åƒ¹
        "å»ºè­°é€²å ´åƒ¹æ ¼": close_last,   # ç•¶å¤©æ”¶ç›¤åƒ¹è¦–ç‚ºå‡è¨­é€²å ´åƒ¹
        "å»ºè­°é€€å ´åƒ¹æ ¼": init_stop,    # ATR åˆå§‹åœæåƒ¹

        # æ¢ä»¶çµæœ / è©•åˆ†
        "è‚¡åƒ¹é«˜æ–¼EMA": bool(cond1),
        "æˆäº¤é‡æ”¾å¤§": bool(cond2),
        "KDåˆç†å€é–“": bool(cond3),
        "è¶¨å‹¢å¼·å‹": bool(cond4),
        "MACDå¤šé ­": bool(cond5),
        "æ³•äºº4é€±è²·è¶…é€šé": bool(cond6),   # åªåšå±•ç¤º
        "æ˜¯å¦ç¬¦åˆ": "ç¬¦åˆ" if entry_pass else "ä¸ç¬¦åˆ",
        "ç¶œåˆè©•åˆ†(score)": score,

        # æ³•äººè³‡è¨Š
        "æ³•äºº4é€±è²·è¶…": inst_4w_sum,
        "æ³•äººå¼·åº¦åˆ†æ•¸": inst_score,

        # å‡ºå ´ç†ç”±
        "å‡ºå ´åŸå› ä»£ç¢¼": ";".join(exit_reasons),
        "å‡ºå ´åŸå› ä¸­æ–‡": ";".join(exit_cn_list),
    }

    conds_map = {
        "cond1": cond1,
        "cond2": cond2,
        "cond3": cond3,
        "cond4": cond4,
        "cond5": cond5,
        "cond6": cond6,
    }

    return metrics, entry_pass, conds_map, exit_reasons


# ============================================================
# å›æ¸¬å·¥å…·ï¼ˆT+1 é–‹ç›¤åƒ¹æ¨¡æ“¬ï¼Œå«æ³•äººï¼‰
# ============================================================

def calc_cagr(start_value: float, end_value: float, years: float) -> float:
    if start_value <= 0 or end_value <= 0 or years <= 0:
        return 0.0
    return (end_value / start_value) ** (1.0 / years) - 1.0


def run_backtest_for_code(df: pd.DataFrame,
                          cfg: Dict[str, Any],
                          inst_series: Optional[pd.Series] = None):
    """
    ç°¡æ˜“å–®æª”å›æ¸¬ï¼ˆT+1 é–‹ç›¤åƒ¹æ¨¡æ“¬ï¼‰ï¼š
    - ç¬¬ i æ ¹ K æ£’æ”¶ç›¤å¾Œï¼Œæ ¹æ“šç•¶å¤©æŒ‡æ¨™æ±ºå®šã€Œéš”å¤©é–‹ç›¤ã€æ˜¯å¦é€²/å‡ºå ´
    - å¯¦éš›æˆäº¤åƒ¹ = ç¬¬ i+1 å¤©é–‹ç›¤åƒ¹ Â± æ»‘åƒ¹
    - å›å‚³ï¼š
        stat: ç¸½å ±é…¬ç‡ / å¹´åŒ–å ±é…¬ç‡ / å‹ç‡...
        trades_detail: æ¯ä¸€ç­†äº¤æ˜“ï¼ˆé€²å‡ºå ´æ—¥æœŸ / åƒ¹æ ¼ / æç›Š / åŸå› ï¼‰
    """
    df = df.sort_index().copy()
    if df.empty:
        return {}, []

    # === åƒæ•¸ ===
    initial_capital = float(cfg.get("backtest_initial_capital", 1_000_000))
    risk_pct        = float(cfg.get("backtest_risk_per_trade", 0.1))
    commission_pct  = float(cfg.get("backtest_commission_pct", 0.001))
    slippage_pct    = float(cfg.get("backtest_slippage_pct", 0.001))

    # === ç‹€æ…‹è®Šæ•¸ ===
    cash        = initial_capital
    position    = 0
    entry_price = 0.0
    entry_date  = None

    equity_curve  = []
    trades_pnl    = []
    trades_detail = []

    closes = df["Close"].astype(float).to_numpy().reshape(-1)
    opens  = df["Open"].astype(float).to_numpy().reshape(-1)

    idx = list(df.index)
    n   = len(idx)

    # å› ç‚ºè¦ç”¨ã€Œéš”å¤©é–‹ç›¤ã€ï¼Œæœ€å¾Œä¸€å¤©æ²’å¾—äº¤æ˜“ï¼Œæ‰€ä»¥åªè·‘åˆ° n-2
    for i in range(50, n - 1):
        sub = df.iloc[: i + 1]          # çµ¦ç­–ç•¥çœ‹çš„æ­·å²ï¼ˆå«ä»Šå¤©ï¼‰
        cur_date  = idx[i]
        next_date = idx[i + 1]

        px_close_today = float(closes[i])
        px_open_next   = float(opens[i + 1])

        # æ³•äººå­åºåˆ—ä¹Ÿåˆ‡åˆ°ç›®å‰ç‚ºæ­¢
        sub_inst = None
        if inst_series is not None:
            sub_inst = inst_series.iloc[: i + 1]

        # æ›´æ–°ã€Œä»Šå¤©æ”¶ç›¤ã€çš„è³‡ç”¢æ·¨å€¼ï¼ˆåªæ˜¯è¨˜éŒ„ç¸¾æ•ˆæ›²ç·šï¼‰
        equity = cash + position * px_close_today if position > 0 else cash
        equity_curve.append(equity)

        # ç”¨åˆ°ç›®å‰ç‚ºæ­¢çš„è³‡æ–™ç®—æŒ‡æ¨™ â†’ æ±ºå®šæ˜¯å¦åœ¨ã€Œæ˜å¤©é–‹ç›¤ã€é€² / å‡ºå ´
        metrics, entry_ok, conds_map, exit_reasons = screen_and_exit(sub, cfg, sub_inst)

        # === æœ‰éƒ¨ä½ï¼šè‹¥ä»Šå¤©å‡ºç¾å‡ºå ´è¨Šè™Ÿ â†’ æ˜å¤©é–‹ç›¤åƒ¹è³£å‡º ===
        if position > 0 and exit_reasons:
            sell_price = px_open_next * (1.0 - slippage_pct)
            gross      = sell_price * position
            fee        = gross * commission_pct
            cash      += gross - fee

            profit = gross - fee - entry_price * position
            trades_pnl.append(profit)

            trades_detail.append({
                "é€²å ´æ—¥æœŸ": entry_date.date().isoformat() if entry_date is not None else "",
                "é€€å ´æ—¥æœŸ": next_date.date().isoformat(),
                "é€²å ´åƒ¹æ ¼": entry_price,
                "é€€å ´åƒ¹æ ¼": sell_price,
                "è‚¡æ•¸": position,
                "æ¯›åˆ©": gross - entry_price * position,
                "æ‰‹çºŒè²»": fee,
                "æ·¨åˆ©": profit,
                "å ±é…¬ç‡": profit / (entry_price * position) if position > 0 else 0.0,
                "å‡ºå ´åŸå› ": ";".join(exit_reasons),
            })

            position    = 0
            entry_price = 0.0
            entry_date  = None
            continue

        # === ç„¡éƒ¨ä½ï¼šè‹¥ä»Šå¤©ç¬¦åˆé€²å ´æ¢ä»¶ â†’ æ˜å¤©é–‹ç›¤åƒ¹è²·é€² ===
        if position == 0 and entry_ok:
            alloc = cash * risk_pct
            if alloc <= 0:
                continue

            buy_price = px_open_next * (1.0 + slippage_pct)
            qty       = int(alloc // buy_price)
            if qty <= 0:
                continue

            cost       = buy_price * qty
            fee        = cost * commission_pct
            total_cost = cost + fee
            if total_cost > cash:
                continue

            cash       -= total_cost
            position    = qty
            entry_price = buy_price
            entry_date  = next_date   # é€²å ´æ—¥ = å¯¦éš›æˆäº¤é‚£å¤©ï¼ˆéš”å¤©ï¼‰

    # === è¿´åœˆè·‘å®Œä½†é‚„æœ‰éƒ¨ä½ â†’ ç”¨æœ€å¾Œä¸€æ ¹ K çš„æ”¶ç›¤åƒ¹å¼·åˆ¶å¹³å€‰ ===
    if position > 0:
        last_date  = idx[-1]
        last_close = float(closes[-1])
        sell_price = last_close * (1.0 - slippage_pct)
        gross      = sell_price * position
        fee        = gross * commission_pct
        cash      += gross - fee

        profit = gross - fee - entry_price * position
        trades_pnl.append(profit)

        trades_detail.append({
            "é€²å ´æ—¥æœŸ": entry_date.date().isoformat() if entry_date is not None else "",
            "é€€å ´æ—¥æœŸ": last_date.date().isoformat(),
            "é€²å ´åƒ¹æ ¼": entry_price,
            "é€€å ´åƒ¹æ ¼": sell_price,
            "è‚¡æ•¸": position,
            "æ¯›åˆ©": gross - entry_price * position,
            "æ‰‹çºŒè²»": fee,
            "æ·¨åˆ©": profit,
            "å ±é…¬ç‡": profit / (entry_price * position) if position > 0 else 0.0,
            "å‡ºå ´åŸå› ": "å¼·åˆ¶å¹³å€‰",
        })

        position    = 0
        entry_price = 0.0
        entry_date  = None

    # === çµ±è¨ˆçµæœ ===
    final_equity = cash if not equity_curve else equity_curve[-1]
    total_return = (final_equity / initial_capital) - 1.0

    n_trades = len(trades_pnl)
    wins     = [p for p in trades_pnl if p > 0]
    losses   = [p for p in trades_pnl if p <= 0]
    win_rate = (len(wins) / n_trades) if n_trades > 0 else 0.0

    days  = (df.index[-1] - df.index[0]).days
    years = days / 365.0 if days > 0 else 0.0
    cagr  = calc_cagr(initial_capital, final_equity, years) if years > 0 else 0.0

    stat = {
        "ç¸½å ±é…¬ç‡": total_return,
        "å¹´åŒ–å ±é…¬ç‡": cagr,
        "äº¤æ˜“æ¬¡æ•¸": n_trades,
        "å‹ç‡": win_rate,
        "å¹³å‡ç²åˆ©": float(np.mean(wins)) if wins else 0.0,
        "å¹³å‡è™§æ": float(np.mean(losses)) if losses else 0.0,
        "æœŸåˆè³‡é‡‘": initial_capital,
        "æœŸæœ«è³‡é‡‘": final_equity,
    }

    return stat, trades_detail


# ============================================================
# è¨­å®šæª”è¼‰å…¥
# ============================================================

def load_config(path: Optional[str]) -> Dict[str, Any]:
    cfg = dict(DEFAULT_CFG)
    if not path:
        return cfg
    text = open(path, "r", encoding="utf-8").read()
    try:
        if HAS_YAML and path.lower().endswith((".yml", ".yaml")):
            data = yaml.safe_load(text)
        else:
            data = json.loads(text)
        if isinstance(data, dict):
            cfg.update(data)
    except Exception as e:
        print(f"[è­¦å‘Š] ç„¡æ³•è§£æè¨­å®šæª” {path}ï¼š{e}ï¼ˆä½¿ç”¨é è¨­ï¼‹éƒ¨åˆ†è¦†å¯«ï¼‰")
    return cfg


# ============================================================
# main
# ============================================================

def main():
    import argparse

    ap = argparse.ArgumentParser(description="å°å£è›‹å°è‚¡çµ‚æ¥µç­–ç•¥ tw_stock_pipeline.py")

    ap.add_argument("--start", type=str, default="2023-01-01")
    ap.add_argument("--end", type=str, default=dt.date.today().isoformat())
    ap.add_argument("--config", type=str, default="config.yaml")
    ap.add_argument("--out", type=str, default="tw_screen_results.csv")
    ap.add_argument("--report_all", action="store_true",
                    help="è¼¸å‡ºå…¨å¸‚å ´ç•¶æ—¥æŒ‡æ¨™å ±è¡¨ tw_all_results.csv")
    ap.add_argument("--codes", type=str,
                    help="åªæƒé€™äº›è‚¡ç¥¨ï¼Œé€—è™Ÿåˆ†éš”ï¼Œä¾‹å¦‚ï¼š2330.TW,2603.TW,5483.TWO")
    # å›æ¸¬
    ap.add_argument("--backtest_codes", type=str,
                    help="åªå°é€™äº›ä»£ç¢¼åšå›æ¸¬ï¼Œé€—è™Ÿåˆ†éš”ï¼Œä¾‹å¦‚ï¼š2330.TW,2603.TW")
    ap.add_argument("--backtest_out", type=str, default="backtest_results.csv")

    args = ap.parse_args()

    cfg = load_config(args.config)
    held_roots = load_held_stocks()

    # è®€æ³•äººè³‡æ–™ï¼ˆæª”æ¡ˆä¸å­˜åœ¨å°±è‡ªå‹•æŠ“ T86ï¼‰
    inst_df: Optional[pd.DataFrame] = None
    inst_path = cfg.get("inst_flow_file", "inst_flow.csv")

    if not os.path.exists(inst_path):
        print(f"âš  æ‰¾ä¸åˆ° {inst_path}ï¼Œè‡ªå‹•å¾ TWSE æŠ“å–ä¸‰å¤§æ³•äººè³‡æ–™ç”¢ç”Ÿâ€¦")
        build_inst_flow(args.start, args.end, inst_path)

    inst_df = load_inst_data(inst_path)
    if inst_df is None:
        print("âš  ç„¡æ³•è¼‰å…¥æ³•äººè³‡æ–™ï¼Œå°‡åªä½¿ç”¨æŠ€è¡“é¢æ¢ä»¶èˆ‡è©•åˆ†")
        cfg["score_w_inst"] = 0.0

    # æº–å‚™è‚¡ç¥¨æ¸…å–®
    if args.codes:
        codes = []
        for part in args.codes.split(","):
            s = part.strip().upper()
            if not s:
                continue
            if s.endswith(".TW") or s.endswith(".TWO"):
                codes.append(s)
            elif s.isdigit():
                codes.append(f"{s}.TW")
        codes = sorted(set(codes))
    else:
        codes = load_all_tw_codes()

    print(f"ğŸ“Œ æœ¬æ¬¡è™•ç†è‚¡ç¥¨æ•¸é‡ï¼š{len(codes)}")

    passed_rows = []
    all_rows = []

    for code in codes:
        print(f"\n=== è™•ç† {code} ===")
        df = load_price(code, args.start, args.end)
        if df is None or df.empty:
            print(f"âŒ ç„¡æ³•å–å¾— {code} åƒ¹æ ¼è³‡æ–™ï¼Œå·²åŠ å…¥é»‘åå–®æˆ–ç•¥é")
            continue

        inst_series = get_inst_series_for_code(inst_df, code, df.index)

        metrics, entry_pass, conds_map, exit_reasons = screen_and_exit(df, cfg, inst_series)
        row = {"ä»£ç¢¼": code, **metrics}
        all_rows.append(row)

        # é€²å ´çµæœå°å‡º
        if entry_pass:
            passed_rows.append(row)
            print(f"âœ… ç¬¦åˆï¼š{code}ï¼ˆscore={metrics['ç¶œåˆè©•åˆ†(score)']:.3f}ï¼‰")
        else:
            # åªåˆ—å‡ºæ²’éçš„äº”å€‹æŠ€è¡“æ¢ä»¶ï¼ˆæ³•äººåªåšåƒè€ƒï¼‰
            failed = [
                name
                for k, name in CN_COND_NAMES.items()
                if k in ("cond1", "cond2", "cond3", "cond4", "cond5")
                and not conds_map.get(k, True)
            ]
            if failed:
                print(f"âŒ ä¸ç¬¦åˆï¼š{code}ï¼ˆæœªéï¼š{', '.join(failed)}ï¼‰")
            else:
                print(f"âŒ ä¸ç¬¦åˆï¼š{code}")

        # Telegram é€²å ´æ¨æ’­
        if entry_pass and cfg.get("notify_on_entry") and cfg.get("telegram_token") and cfg.get("telegram_chat_id"):
            msg = format_entry_card(code, metrics)
            tg_send(msg, cfg)

        # Telegram å‡ºå ´æ¨æ’­ï¼ˆåªå°æŒè‚¡æ¸…å–®å…§çš„ä»£ç¢¼ï¼‰
        if exit_reasons and cfg.get("notify_on_exit") and cfg.get("telegram_token") and cfg.get("telegram_chat_id"):
            m = re.match(r"(\d+)", code)
            root = m.group(1) if m else ""
            if root and root in held_roots:
                msg = format_exit_card(code, metrics, exit_reasons)
                tg_send(msg, cfg)

    # ===== çµæœè¼¸å‡º =====
    if passed_rows:
        df_pass = pd.DataFrame(passed_rows)
        df_pass = df_pass.sort_values(["æ—¥æœŸ", "ç¶œåˆè©•åˆ†(score)"], ascending=[True, False])
        df_pass.to_csv(args.out, index=False, encoding="utf-8-sig")
        print(f"\nğŸ‰ å·²è¼¸å‡ºç¬¦åˆé€²å ´æ¸…å–® â†’ {args.out}")
    else:
        print("\nâš  ç›®å‰ç„¡ç¬¦åˆæ­¤é–€æª»ä¹‹æ¨™çš„ã€‚")

    if args.report_all and all_rows:
        df_all = pd.DataFrame(all_rows)
        df_all.to_csv("tw_all_results.csv", index=False, encoding="utf-8-sig")
        print("ğŸ“„ å·²è¼¸å‡ºå…¨å¸‚å ´å®Œæ•´å ±è¡¨ â†’ tw_all_results.csv")

    # ===== å›æ¸¬æµç¨‹ï¼ˆé¸ç”¨ï¼‰ =====
    if cfg.get("enable_backtest", False) and args.backtest_codes:
        bt_codes = [c.strip().upper() for c in args.backtest_codes.split(",") if c.strip()]
        bt_rows: List[Dict[str, Any]] = []
        all_trades: List[Dict[str, Any]] = []

        print(f"\nğŸ“Š é–‹å§‹å›æ¸¬ï¼ˆå…± {len(bt_codes)} æª”ï¼‰ï¼š{', '.join(bt_codes)}")

        for code in bt_codes:
            print(f"  â–¶ å›æ¸¬ {code} ...")
            df_bt = load_price(code, args.start, args.end)
            if df_bt is None or df_bt.empty:
                print(f"    âš  ç„¡æ³•å–å¾— {code} è³‡æ–™ï¼Œç•¥é")
                continue

            inst_series_bt = get_inst_series_for_code(inst_df, code, df_bt.index)

            stat, trades_detail = run_backtest_for_code(df_bt, cfg, inst_series_bt)
            if not stat:
                print(f"    âš  {code} ç„¡æ³•è¨ˆç®—å›æ¸¬çµæœï¼Œç•¥é")
                continue

            # å½™ç¸½çµæœ
            row = {"ä»£ç¢¼": code}
            row.update(stat)
            bt_rows.append(row)

            # å–®ç­†äº¤æ˜“æ˜ç´°
            for t in trades_detail:
                t_row = {"ä»£ç¢¼": code}
                t_row.update(t)
                all_trades.append(t_row)

        # è¼¸å‡ºæ¯ä¸€ç­†äº¤æ˜“æ˜ç´°
        if all_trades:
            df_trades = pd.DataFrame(all_trades)
            df_trades.to_csv("backtest_trades_detail.csv", index=False, encoding="utf-8-sig")
            print("âœ… å·²è¼¸å‡ºæ¯ä¸€ç­†äº¤æ˜“æ˜ç´° â†’ backtest_trades_detail.csv")
        else:
            print("âš  æ²’æœ‰ä»»ä½•äº¤æ˜“ç´€éŒ„å¯è¼¸å‡ºï¼ˆå¯èƒ½å®Œå…¨æ²’è§¸ç™¼é€²å‡ºå ´æ¢ä»¶ï¼‰")

        # è¼¸å‡ºæ¯æª”å›æ¸¬æ‘˜è¦
        if bt_rows:
            df_bt = pd.DataFrame(bt_rows)
            df_bt["ç¸½å ±é…¬ç‡(%)"] = df_bt["ç¸½å ±é…¬ç‡"] * 100
            df_bt["å¹´åŒ–å ±é…¬ç‡(%)"] = df_bt["å¹´åŒ–å ±é…¬ç‡"] * 100
            df_bt["å‹ç‡(%)"] = df_bt["å‹ç‡"] * 100
            df_bt.to_csv(args.backtest_out, index=False, encoding="utf-8-sig")
            print(f"âœ… å›æ¸¬çµæœå·²è¼¸å‡ºï¼š{args.backtest_out}")
        else:
            print("âš  æ²’æœ‰å¯ç”¨çš„å›æ¸¬çµæœï¼ˆbt_rows ç‚ºç©ºï¼‰")

if __name__ == "__main__":
    main()
